{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GENERAL INFORMATION    -  ARCHITECTURE\n",
        "\n",
        "\n",
        "\n",
        "The metacognitive network consists of 2 interconnected networks:\n",
        "\n",
        "1. A three layers backpropagation feddforward first-order network ( MAIN TASK)\n",
        "2. A second order network that continously evaluates the performance of the first order network   =   hidden unit  +   two output nodes(HIGH or LOW wagers)\n",
        "\n",
        "*In both cases a winner-take-all algorithm in the output was used (all output activations ranging from 0.0. to 1.0)\n",
        "\n",
        "\n",
        "Main Differences of the particular metacognitive network:\n",
        "\n",
        "1. The nature of the higher order representation\n",
        "2. The implementation of \"low\" and \"high\" awareness conditions"
      ],
      "metadata": {
        "id": "rZG8quwc84Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARCHITECTURE - FIRST ORDER NETWORK\n",
        "\n",
        "1. The first order network is an autoassociator, complemented by a winner-take-all at the output = Re-representation of the input = Creates a bimodal distribution of inputs\n",
        "\n",
        "*What a non-conscious learning mechanism can do\n",
        "\n",
        "\n",
        "- It is a backpropagation autoassociator\n",
        "- First, it consists of a 100-unit input layer\n",
        "- It is connected to a layer of 60 hidden units\n",
        "- Then, it is finally connected to a 100-unit output layer\n"
      ],
      "metadata": {
        "id": "vhWWvCXH-Btv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARCHITECTURE - SECOND ORDER NETWORK\n",
        "\n",
        "2. The second order network's hidden units consists of a comparator matrix\n",
        "- It is a feedforward backpropagation network\n",
        "- The input is a 100-unit comparison matrix ( match between the first-order input and output layers )"
      ],
      "metadata": {
        "id": "ERi77z9CE0YF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROPERTIES\n",
        "1. development of the comparison patterns is automatic and unsupervised (that is, not driven by feedback)\n",
        "2. the second-order networkâ€™s access to these patterns for wagering is learned in a pre-training phase, independent of specific first-order patterns or training and testing tasks."
      ],
      "metadata": {
        "id": "48QXKzH-Cmpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------PRE-TRAINING PHASE-----------------------------------\n",
        "\n",
        "1. Each pre-trained on 200 patters\n",
        "2. 150 epochs were used\n"
      ],
      "metadata": {
        "id": "6WW_9gb3C0G3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network pre-training set consisted of 200 patterns\n",
        "- half of which represented mere noise (unit activations chosen random between 0.0 and 0.02)\n",
        "- half of which represented a possible stimulus (for each pattern, 99 out of 100 units had an activation between 0.0 and 0.02, and one unit had an activation between 0.0 and 1.0)"
      ],
      "metadata": {
        "id": "5uJ3LWUZNWP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------\n",
        "TESING PHASE    -  TESTING CONDITIONS\n",
        "\n",
        "the network was tested on three different conditions (different degrees and nature of blindness)\n",
        "\n",
        "-----------------------------------------------------------------------------\n",
        "\n",
        "1. Suprathreshold stimulus: same as in the 200 patterns of the pre-training\n"
      ],
      "metadata": {
        "id": "onRFe5bmD06H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Subthreshold stimulus (representing the Blindsight condition)\n",
        "- noisenoise (+ 0.0012) added to every input on the first-order network except the one representing the stimulus\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QlT2xmAUR_2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Low vision\n",
        "- reducing the activation of the stimuli to (0.0 , 0.3)\n"
      ],
      "metadata": {
        "id": "KBS9RkKLScZT"
      }
    }
  ]
}