{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The first-order network in the Iowa Gambling Task simulation is a three-layer backpropagation feedforward network. It performs the main task of deck selection based on the outcomes of the cards. Each trial, the first-order network selects one of four decks of cards, each with different pay-offs. The network's input consists of the last selected deck (represented by one of the input units activated to 1.0 and the others to 0.0) and the outcome of the last card (win or loss)\n",
        "\n",
        "\n",
        "Main Differences of the particular metacognitive network:\n",
        "\n",
        "1. the Iowa Gambling task requires participants to initially\n",
        "explore the material before being able to create any\n",
        "representation about the decks’ yields. The resulting metarepresentations\n",
        "are thus necessarily dependent on this\n",
        "exploration phase.\n",
        "\n",
        "2. participants receive feedback\n",
        "on each trial about the quality of their wagering, as the turning\n",
        "of the card immediately reveals whether and how much\n",
        "is won. As a consequence, participants can use this feedback\n",
        "to unconsciously optimize not only their deck selection, but\n",
        "also their wagering."
      ],
      "metadata": {
        "id": "rZG8quwc84Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARCHITECTURE - FIRST ORDER NETWORK\n",
        "\n",
        "1. The first-order network is an autoassociator, complemented by a winner-take-all at the output = Re-representation of the input = Creates a bimodal distribution of inputs\n",
        "\n",
        "- It is a backpropagation autoassociator.\n",
        "- Consists of a 5-unit input layer (representing the last selected deck and the last obtained outcome).\n",
        "- Input units are set to 1.0 for the corresponding unit (selected deck or outcome) and 0.0 for the others.\n",
        "- Connected to a layer of 40 hidden units.\n",
        "- Finally connected to a 4-unit output layer, representing the four decks.\n",
        "- Initial connection weights were between -1.0 and 1.0.\n"
      ],
      "metadata": {
        "id": "vhWWvCXH-Btv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARCHITECTURE - SECOND ORDER NETWORK\n",
        "\n",
        "2. The second-order network's hidden units consist of a comparator matrix:\n",
        "\n",
        "- The input to the second-order network is a 40-unit comparison matrix, representing the match between the first-order network's input and output layers.\n",
        "- This comparison matrix effectively quantifies the accuracy or error of the first-order network's internal knowledge.\n",
        "- Initial connection weights were between 0.0 and 0.1.\n"
      ],
      "metadata": {
        "id": "ERi77z9CE0YF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Wagering specifics and Learning:\n",
        "\n",
        "- The second-order network's metarepresentations rely on the information from the first-order network's hidden units to determine wagering decisions.\n",
        "- All network weights in the second-order network are subject to learning, allowing the network to adapt based on the information from the first-order network's hidden units.\n",
        "- The second-order network's learning rate was set at 0.0003 in the \"Low Consciousness\" condition and 0.015 in the \"High Consciousness\" condition."
      ],
      "metadata": {
        "id": "48QXKzH-Cmpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------\n",
        "PATTERNS\n",
        "\n",
        "In the simulated Iowa Gambling Task:\n",
        "\n",
        "1. Deck Characteristics:\n",
        "\n",
        "- Two decks had a 70% win rate, while the other two had a 30% win rate.\n",
        "\n",
        "\n",
        "2. First-Order Network's Input Patterns:\n",
        "\n",
        "- Each trial's input pattern at time \"t\" was a modified version of the previous output pattern (\"t-1\").\n",
        "- The strongest activated unit from the previous output was chosen.\n",
        "- This modified pattern was combined with win/loss information.\n",
        "\n",
        "\n",
        "3. First-Order Network's Target Patterns:\n",
        "\n",
        "- Targets encouraged exploration.\n",
        "- In rewards, the selected deck's output was 1.0, others 0.0.\n",
        "- In losses, the selected deck's output was 0.0, others 1.0.\n",
        "\n",
        "\n",
        "4. Second-Order Network's Target Patterns:\n",
        "\n",
        "- Linked to first-order network's choices.\n",
        "- If first-order chose winning card, second-order's target: \"high wager\" = 1.0, \"low wager\" = 0.0.\n",
        "- If first-order chose losing card, second-order's target: \"high wager\" = 0.0, \"low wager\" = 1.0.\n",
        "- Properties of decks not explicitly revealed to networks, fostering exploration.\n",
        "--------------------------------------"
      ],
      "metadata": {
        "id": "-jmf9tyTE6el"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------\n",
        "TRAININING PHASE\n",
        "\n",
        "1. 30 networks were trained for 2000 trials (200 epochs) in total.\n",
        "2. The training was conducted under two conditions, each involving a different degree of awareness.\n",
        "3. In both groups of 15 networks, the first-order network learning rate was set at 0.002.\n",
        "4. In the \"Low Consciousness\" condition, the second-order network’s learning rate was 0.0003.\n",
        "5. In the \"High Consciousness\" condition, the second-order network’s learning rate was 0.015.\n",
        "------------------------------------------------------------------------------\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uq2ZAh_QYQio"
      }
    }
  ]
}